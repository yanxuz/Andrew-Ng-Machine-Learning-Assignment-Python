{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sci\n",
    "import sklearn as sk\n",
    "import re #regular expression for e-mail processing\n",
    "from stemming.porter2 import stem\n",
    "import nltk, nltk.stem.porter\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    " \n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "def getVocabDict(reverse=False):\n",
    "    vocab_dict = {}\n",
    "    with open(\"vocab.txt\") as f:\n",
    "        for line in f:\n",
    "            (val, key) = line.split()\n",
    "            if not reverse:\n",
    "                vocab_dict[key] = int(val)\n",
    "            else:\n",
    "                vocab_dict[int(val)] = key                \n",
    "    return vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mapping the email\n",
    "def preProcess( email ):\n",
    "    # lower-casing\n",
    "    email = email.lower()\n",
    "    # HTML tags striping, HTML tags are with <>\n",
    "    email = re.sub('<[^<>]+>', ' ', email);\n",
    "    # Normalizing URLs:\n",
    "    email = re.sub('(http|https)://[^\\s]*', 'httpaddr', email)\n",
    "    # Normalizing Email adress\n",
    "    email = re.sub('[^\\s]+@[^\\s]+','emailaddr', email)\n",
    "    # Normalizing numbers\n",
    "    email = re.sub('[0-9]+','number', email)\n",
    "    # Normalizing dollars\n",
    "    email = re.sub('[$]+','dollar', email)   \n",
    "    return(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "def tokenize( email ):\n",
    "    # Word Stemming\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()    \n",
    "    # split the email\n",
    "    tokens = re.split('[^0-9a-z]', email)\n",
    "    # iterate each token\n",
    "    tokenlist = []\n",
    "    for token in tokens:\n",
    "        #Use the Porter stemmer to stem the word\n",
    "        stemmed = stemmer.stem( token )\n",
    "        #Store a list of all stemmed words\n",
    "        if len(stemmed) > 0:\n",
    "            tokenlist.append(stemmed)    \n",
    "    return(tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vocabularize\n",
    "def vocabularize( email , vocab_dict):\n",
    "    return([vocab_dict[token] for token in email if token in vocab_dict])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process email\n",
    "def processEmail( email ):\n",
    "    # preprocessing\n",
    "    email = preProcess(email)\n",
    "    # tokenize\n",
    "    email = tokenize(email)\n",
    "    # mapping to vocabulary\n",
    "    vocab_dict = getVocabDict(reverse=False)\n",
    "    email = vocabularize(email, vocab_dict)\n",
    "    # extract feature\n",
    "    n_vocab = len(vocab_dict)\n",
    "    feature = np.zeros((n_vocab,1))\n",
    "    for idx in email:\n",
    "        feature[idx-1] = 1\n",
    "    return(feature.reshape(1,-1))\n",
    "email = open( 'emailSample1.txt', 'r' ).read()\n",
    "email = processEmail(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load traning and test data\n",
    "# Training set\n",
    "datafile = 'spamTrain.mat'\n",
    "mat = sci.io.loadmat( datafile )\n",
    "X, y = mat['X'], mat['y']\n",
    "\n",
    "# Test set\n",
    "datafile = 'spamTest.mat'\n",
    "mat = sci.io.loadmat( datafile )\n",
    "Xtest, ytest = mat['Xtest'], mat['ytest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.825\n",
      "98.9\n"
     ]
    }
   ],
   "source": [
    "# initialize a SVM\n",
    "my_svm = sk.svm.SVC(C=0.1,kernel='linear')\n",
    "# train the SVM\n",
    "my_svm.fit(X,y.ravel())\n",
    "# test the SVM\n",
    "trained_score=my_svm.score(X,y.ravel())\n",
    "tested_score=my_svm.score(Xtest,ytest.ravel())\n",
    "print(trained_score*100.0)\n",
    "print(tested_score*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['otherwis', 'clearli', 'remot', 'gt', 'visa', 'base', 'doesn', 'wife', 'previous', 'player', 'mortgag', 'natur', 'll', 'futur', 'hot']\n",
      "['http', 'toll', 'xp', 'ratio', 'august', 'unsubscrib', 'useless', 'numberth', 'round', 'linux', 'datapow', 'wrong', 'urgent', 'that', 'spam']\n"
     ]
    }
   ],
   "source": [
    "# top spam words\n",
    "vocab_dict_reverse = getVocabDict(reverse=True)\n",
    "param_sorted=np.argsort(my_svm.coef_,axis=None)[::-1]\n",
    "top_spam_words=[ vocab_dict_reverse[x] for x in param_sorted[:15] ]\n",
    "bottom_spam_words=[ vocab_dict_reverse[x] for x in param_sorted[-15:] ]\n",
    "print(top_spam_words)\n",
    "print(bottom_spam_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# try own emails\n",
    "print(my_svm.predict(processEmail(open('emailSample2.txt','r').read())))\n",
    "print(my_svm.predict(processEmail(open('spamSample1.txt','r').read())))\n",
    "print(my_svm.predict(processEmail(open('spamSample2.txt','r').read())))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
